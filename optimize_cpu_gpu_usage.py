#!/usr/bin/env python3
"""
Optimize CPU/GPU Resource Utilization

This script implements optimal resource utilization by:
1. Running CPU tasks while GPU is busy
2. Parallel processing pipelines
3. Asynchronous operations
4. Multi-threading for different components
"""

import sys
import logging
import time
import threading
import asyncio
import concurrent.futures
from pathlib import Path
from typing import Dict, Any, List, Optional, Callable
from dataclasses import dataclass
from queue import Queue, Empty
import psutil

# Add src to Python path
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


@dataclass
class ResourceTask:
    """A task that can be executed on CPU or GPU."""
    task_id: str
    task_type: str  # "generation", "preprocessing", "postprocessing", "analysis"
    resource_type: str  # "cpu", "gpu", "mixed"
    priority: int
    estimated_time: float
    task_func: Callable
    args: tuple
    kwargs: dict


class ResourceOptimizer:
    """Optimizes CPU/GPU resource utilization for maximum throughput."""
    
    def __init__(self, max_cpu_workers: int = None, max_gpu_workers: int = 1):
        self.max_cpu_workers = max_cpu_workers or min(8, psutil.cpu_count())
        self.max_gpu_workers = max_gpu_workers
        
        # Task queues
        self.cpu_queue = Queue()
        self.gpu_queue = Queue()
        self.mixed_queue = Queue()
        
        # Worker pools
        self.cpu_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=self.max_cpu_workers,
            thread_name_prefix="CPU-Worker"
        )
        self.gpu_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=self.max_gpu_workers,
            thread_name_prefix="GPU-Worker"
        )
        
        # Resource monitoring
        self.cpu_busy = threading.Event()
        self.gpu_busy = threading.Event()
        self.active_tasks = {}
        
        # Statistics
        self.stats = {
            'cpu_tasks_completed': 0,
            'gpu_tasks_completed': 0,
            'total_cpu_time': 0.0,
            'total_gpu_time': 0.0,
            'parallel_efficiency': 0.0
        }
        
        logger.info(f"ResourceOptimizer initialized: {self.max_cpu_workers} CPU workers, {self.max_gpu_workers} GPU workers")
    
    def submit_task(self, task: ResourceTask) -> concurrent.futures.Future:
        """Submit a task for optimal resource utilization."""
        logger.info(f"Submitting task {task.task_id} ({task.resource_type})")
        
        if task.resource_type == "cpu":
            return self._submit_cpu_task(task)
        elif task.resource_type == "gpu":
            return self._submit_gpu_task(task)
        elif task.resource_type == "mixed":
            return self._submit_mixed_task(task)
        else:
            raise ValueError(f"Unknown resource type: {task.resource_type}")
    
    def _submit_cpu_task(self, task: ResourceTask) -> concurrent.futures.Future:
        """Submit CPU-only task."""
        def wrapped_task():
            start_time = time.time()
            self.cpu_busy.set()
            
            try:
                logger.info(f"ğŸ–¥ï¸ Starting CPU task {task.task_id}")
                result = task.task_func(*task.args, **task.kwargs)
                
                execution_time = time.time() - start_time
                self.stats['cpu_tasks_completed'] += 1
                self.stats['total_cpu_time'] += execution_time
                
                logger.info(f"âœ… CPU task {task.task_id} completed in {execution_time:.2f}s")
                return result
                
            except Exception as e:
                logger.error(f"âŒ CPU task {task.task_id} failed: {e}")
                raise
            finally:
                self.cpu_busy.clear()
        
        return self.cpu_executor.submit(wrapped_task)
    
    def _submit_gpu_task(self, task: ResourceTask) -> concurrent.futures.Future:
        """Submit GPU task with CPU work scheduling."""
        def wrapped_task():
            start_time = time.time()
            self.gpu_busy.set()
            
            try:
                logger.info(f"ğŸ® Starting GPU task {task.task_id}")
                
                # Schedule CPU work while GPU is busy
                self._schedule_cpu_work_during_gpu()
                
                result = task.task_func(*task.args, **task.kwargs)
                
                execution_time = time.time() - start_time
                self.stats['gpu_tasks_completed'] += 1
                self.stats['total_gpu_time'] += execution_time
                
                logger.info(f"âœ… GPU task {task.task_id} completed in {execution_time:.2f}s")
                return result
                
            except Exception as e:
                logger.error(f"âŒ GPU task {task.task_id} failed: {e}")
                raise
            finally:
                self.gpu_busy.clear()
        
        return self.gpu_executor.submit(wrapped_task)
    
    def _submit_mixed_task(self, task: ResourceTask) -> concurrent.futures.Future:
        """Submit mixed CPU/GPU task with optimal scheduling."""
        def wrapped_task():
            start_time = time.time()
            
            try:
                logger.info(f"âš¡ Starting mixed task {task.task_id}")
                result = task.task_func(*task.args, **task.kwargs)
                
                execution_time = time.time() - start_time
                logger.info(f"âœ… Mixed task {task.task_id} completed in {execution_time:.2f}s")
                return result
                
            except Exception as e:
                logger.error(f"âŒ Mixed task {task.task_id} failed: {e}")
                raise
        
        return self.cpu_executor.submit(wrapped_task)
    
    def _schedule_cpu_work_during_gpu(self):
        """Schedule CPU work to run while GPU is busy."""
        # This runs in a separate thread to not block GPU work
        def cpu_background_work():
            logger.info("ğŸ”„ Starting background CPU work while GPU is busy")
            
            # Example CPU tasks that can run during GPU generation:
            # 1. Preprocess next batch
            # 2. Analyze previous results
            # 3. Update statistics
            # 4. Prepare output files
            
            cpu_tasks = [
                self._cpu_preprocess_next_batch,
                self._cpu_analyze_previous_results,
                self._cpu_update_statistics,
                self._cpu_cleanup_temp_files
            ]
            
            for cpu_task in cpu_tasks:
                if not self.gpu_busy.is_set():
                    break  # GPU finished, stop background work
                
                try:
                    cpu_task()
                except Exception as e:
                    logger.warning(f"Background CPU task failed: {e}")
                
                time.sleep(0.1)  # Small delay between tasks
        
        # Start background CPU work in a separate thread
        threading.Thread(target=cpu_background_work, daemon=True).start()
    
    def _cpu_preprocess_next_batch(self):
        """CPU task: Preprocess data for next generation."""
        logger.debug("ğŸ”§ CPU: Preprocessing next batch")
        # Simulate preprocessing work
        time.sleep(0.5)
        # In real implementation: prepare prompts, validate inputs, etc.
    
    def _cpu_analyze_previous_results(self):
        """CPU task: Analyze previous generation results."""
        logger.debug("ğŸ“Š CPU: Analyzing previous results")
        # Simulate analysis work
        time.sleep(0.3)
        # In real implementation: calculate quality metrics, detect issues, etc.
    
    def _cpu_update_statistics(self):
        """CPU task: Update system statistics."""
        logger.debug("ğŸ“ˆ CPU: Updating statistics")
        # Simulate statistics update
        time.sleep(0.2)
        # In real implementation: update performance metrics, resource usage, etc.
    
    def _cpu_cleanup_temp_files(self):
        """CPU task: Clean up temporary files."""
        logger.debug("ğŸ§¹ CPU: Cleaning up temp files")
        # Simulate cleanup work
        time.sleep(0.1)
        # In real implementation: remove old temp files, clear caches, etc.
    
    def get_resource_utilization(self) -> Dict[str, Any]:
        """Get current resource utilization statistics."""
        total_time = max(self.stats['total_cpu_time'], self.stats['total_gpu_time'])
        
        if total_time > 0:
            cpu_utilization = (self.stats['total_cpu_time'] / total_time) * 100
            gpu_utilization = (self.stats['total_gpu_time'] / total_time) * 100
            
            # Calculate parallel efficiency (how much overlap we achieved)
            overlap_time = min(self.stats['total_cpu_time'], self.stats['total_gpu_time'])
            parallel_efficiency = (overlap_time / total_time) * 100 if total_time > 0 else 0
        else:
            cpu_utilization = gpu_utilization = parallel_efficiency = 0
        
        return {
            'cpu_tasks_completed': self.stats['cpu_tasks_completed'],
            'gpu_tasks_completed': self.stats['gpu_tasks_completed'],
            'total_cpu_time': self.stats['total_cpu_time'],
            'total_gpu_time': self.stats['total_gpu_time'],
            'cpu_utilization_percent': cpu_utilization,
            'gpu_utilization_percent': gpu_utilization,
            'parallel_efficiency_percent': parallel_efficiency,
            'cpu_busy': self.cpu_busy.is_set(),
            'gpu_busy': self.gpu_busy.is_set()
        }
    
    def shutdown(self):
        """Shutdown the resource optimizer."""
        logger.info("Shutting down ResourceOptimizer...")
        self.cpu_executor.shutdown(wait=True)
        self.gpu_executor.shutdown(wait=True)


class OptimizedGenerationPipeline:
    """Generation pipeline optimized for CPU/GPU resource utilization."""
    
    def __init__(self):
        self.resource_optimizer = ResourceOptimizer()
        self.system = None
        
    def initialize_system(self):
        """Initialize the AI generation system."""
        try:
            from src.core.system_integration import SystemIntegration
            from src.core.interfaces import ComplianceMode
            
            self.system = SystemIntegration()
            
            config = {
                "data_dir": "data",
                "models_dir": "models",
                "experiments_dir": "experiments",
                "cache_dir": "cache",
                "logs_dir": "logs",
                "auto_detect_hardware": True,
                "max_concurrent_generations": 1
            }
            
            logger.info("âš™ï¸ Initializing optimized generation system...")
            success = self.system.initialize(config)
            
            if success:
                logger.info("âœ… System initialized successfully")
                return True
            else:
                logger.error("âŒ System initialization failed")
                return False
                
        except Exception as e:
            logger.error(f"âŒ System initialization failed: {e}")
            return False
    
    def generate_with_optimal_resources(self, prompts: List[str]) -> List[Any]:
        """Generate images with optimal CPU/GPU resource utilization."""
        if not self.system:
            raise RuntimeError("System not initialized")
        
        logger.info(f"ğŸš€ Starting optimized generation for {len(prompts)} prompts")
        
        # Create tasks for each generation
        tasks = []
        futures = []
        
        for i, prompt in enumerate(prompts):
            # GPU task: Main generation
            gpu_task = ResourceTask(
                task_id=f"generation_{i}",
                task_type="generation",
                resource_type="gpu",
                priority=1,
                estimated_time=30.0,
                task_func=self._generate_single_image,
                args=(prompt, i),
                kwargs={}
            )
            
            # CPU task: Preprocessing (can run in parallel)
            cpu_task = ResourceTask(
                task_id=f"preprocess_{i}",
                task_type="preprocessing",
                resource_type="cpu",
                priority=2,
                estimated_time=2.0,
                task_func=self._preprocess_prompt,
                args=(prompt, i),
                kwargs={}
            )
            
            # Submit tasks
            gpu_future = self.resource_optimizer.submit_task(gpu_task)
            cpu_future = self.resource_optimizer.submit_task(cpu_task)
            
            futures.append((gpu_future, cpu_future))
        
        # Collect results
        results = []
        for i, (gpu_future, cpu_future) in enumerate(futures):
            try:
                # Wait for preprocessing to complete
                preprocess_result = cpu_future.result(timeout=10)
                logger.info(f"âœ… Preprocessing {i} completed")
                
                # Wait for generation to complete
                generation_result = gpu_future.result(timeout=120)
                logger.info(f"âœ… Generation {i} completed")
                
                results.append(generation_result)
                
            except Exception as e:
                logger.error(f"âŒ Task {i} failed: {e}")
                results.append(None)
        
        # Show resource utilization stats
        stats = self.resource_optimizer.get_resource_utilization()
        logger.info(f"ğŸ“Š Resource Utilization Stats:")
        logger.info(f"   CPU Tasks: {stats['cpu_tasks_completed']}")
        logger.info(f"   GPU Tasks: {stats['gpu_tasks_completed']}")
        logger.info(f"   CPU Time: {stats['total_cpu_time']:.2f}s")
        logger.info(f"   GPU Time: {stats['total_gpu_time']:.2f}s")
        logger.info(f"   Parallel Efficiency: {stats['parallel_efficiency_percent']:.1f}%")
        
        return results
    
    def _generate_single_image(self, prompt: str, index: int):
        """Generate a single image (GPU task)."""
        logger.info(f"ğŸ¨ Generating image {index}: '{prompt[:30]}...'")
        
        from src.core.interfaces import ComplianceMode
        
        result = self.system.execute_complete_generation_workflow(
            prompt=prompt,
            conversation_id=f"optimized_{index}",
            compliance_mode=ComplianceMode.RESEARCH_SAFE,
            additional_params={
                'width': 512,
                'height': 512,
                'num_inference_steps': 20,
                'guidance_scale': 7.5,
                'force_real_generation': True
            }
        )
        
        return result
    
    def _preprocess_prompt(self, prompt: str, index: int):
        """Preprocess prompt (CPU task)."""
        logger.info(f"ğŸ”§ Preprocessing prompt {index}")
        
        # Simulate CPU-intensive preprocessing
        processed_prompt = prompt.strip().lower()
        
        # Add some CPU work (text analysis, validation, etc.)
        word_count = len(processed_prompt.split())
        char_count = len(processed_prompt)
        
        # Simulate more CPU work
        time.sleep(1.0)  # Simulate processing time
        
        return {
            'original_prompt': prompt,
            'processed_prompt': processed_prompt,
            'word_count': word_count,
            'char_count': char_count,
            'index': index
        }
    
    def cleanup(self):
        """Clean up resources."""
        if self.resource_optimizer:
            self.resource_optimizer.shutdown()
        if self.system:
            self.system.cleanup()


def test_resource_optimization():
    """Test optimal resource utilization."""
    logger.info("ğŸš€ Testing Optimal CPU/GPU Resource Utilization")
    logger.info("="*60)
    
    pipeline = OptimizedGenerationPipeline()
    
    try:
        # Initialize system
        if not pipeline.initialize_system():
            logger.error("âŒ Failed to initialize system")
            return False
        
        # Test prompts
        test_prompts = [
            "a red apple on a white background",
            "a beautiful sunset over mountains",
            "a cute cat sitting by a window",
            "a futuristic city skyline at night"
        ]
        
        logger.info(f"ğŸ¯ Testing with {len(test_prompts)} prompts")
        
        # Monitor system resources
        import psutil
        process = psutil.Process()
        
        start_time = time.time()
        start_cpu_percent = psutil.cpu_percent(interval=1)
        
        # Run optimized generation
        results = pipeline.generate_with_optimal_resources(test_prompts)
        
        end_time = time.time()
        end_cpu_percent = psutil.cpu_percent(interval=1)
        
        total_time = end_time - start_time
        
        # Analyze results
        successful_results = [r for r in results if r and r.success]
        
        logger.info(f"\nğŸ“Š OPTIMIZATION RESULTS:")
        logger.info(f"   Total Time: {total_time:.2f}s")
        logger.info(f"   Successful Generations: {len(successful_results)}/{len(test_prompts)}")
        logger.info(f"   Average CPU Usage: {(start_cpu_percent + end_cpu_percent) / 2:.1f}%")
        
        if len(successful_results) > 0:
            avg_generation_time = sum(r.generation_time for r in successful_results) / len(successful_results)
            logger.info(f"   Average Generation Time: {avg_generation_time:.2f}s")
            
            # Calculate throughput
            throughput = len(successful_results) / total_time
            logger.info(f"   Throughput: {throughput:.2f} images/second")
        
        # Get final resource stats
        stats = pipeline.resource_optimizer.get_resource_utilization()
        logger.info(f"\nğŸ”§ RESOURCE UTILIZATION:")
        logger.info(f"   Parallel Efficiency: {stats['parallel_efficiency_percent']:.1f}%")
        logger.info(f"   CPU Tasks Completed: {stats['cpu_tasks_completed']}")
        logger.info(f"   GPU Tasks Completed: {stats['gpu_tasks_completed']}")
        
        if stats['parallel_efficiency_percent'] > 50:
            logger.info("âœ… Good parallel efficiency achieved!")
        else:
            logger.warning("âš ï¸ Low parallel efficiency - room for improvement")
        
        return len(successful_results) > len(test_prompts) // 2
        
    except Exception as e:
        logger.error(f"âŒ Resource optimization test failed: {e}")
        return False
    finally:
        pipeline.cleanup()


def main():
    """Run resource optimization tests."""
    success = test_resource_optimization()
    
    if success:
        logger.info("\nğŸ‰ RESOURCE OPTIMIZATION SUCCESSFUL!")
        logger.info("ğŸ’ª CPU and GPU are now working together efficiently")
        logger.info("âš¡ Maximum throughput achieved through parallel processing")
    else:
        logger.error("\nğŸ’¥ Resource optimization needs improvement")
        logger.info("ğŸ’¡ Consider adjusting task scheduling and parallelization")
    
    return success


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)